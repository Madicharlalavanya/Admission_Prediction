# -*- coding: utf-8 -*-
"""admission prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ad1bH007hBEvAs_Y9ZZuNsGC7YxTIRbm
"""

import pandas as pd

data=pd.read_csv('Admission_Predict.csv')

data.head()

data.tail()

data.shape



print(data.shape[0])
print(data.shape[1])

data.info()

data.isnull().sum()

data.describe()

data.columns



data=data.drop('Serial No.',axis=1)

data.columns

data.head(1)

X=data.drop('Chance of Admit ',axis=1)

y=data['Chance of Admit ']

from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=42)

y_train

data.head()

from sklearn.preprocessing import StandardScaler

sc=StandardScaler()

X_train=sc.fit_transform(X_train)
X_test=sc.transform(X_test)

X_train

data.head()

from sklearn.linear_model import LinearRegression
from sklearn import svm
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor

lr=LinearRegression()
lr.fit(X_train,y_train)

svm=SVR()
svm.fit(X_train,y_train)

rf=RandomForestRegressor()
rf.fit(X_train,y_train)

gr=GradientBoostingRegressor()
gr.fit(X_train,y_train)

y_pred1=lr.predict(X_test)
y_pred2=svm.predict(X_test)
y_pred3=rf.predict(X_test)
y_pred4=gr.predict(X_test)

from sklearn import metrics

score1=metrics.r2_score(y_test,y_pred1)
score2=metrics.r2_score(y_test,y_pred2)
score3=metrics.r2_score(y_test,y_pred3)
score4=metrics.r2_score(y_test,y_pred4)

final_data =pd.DataFrame({'Models':['LR','SVR','RF','GR'],'R2_score':[score1,score2,score3,score4]})

final_data

import seaborn as sns

sns.barplot(x=final_data['Models'], y=final_data['R2_score'])

data.head()

import numpy as np

y_train=[1 if value>0.8 else 0 for value in y_train]
y_test=[1 if value>0.8 else 0 for value in y_test]

y_train=np.array(y_train)
y_test=np.array(y_test)

y_train

from sklearn.linear_model import LogisticRegression
from sklearn import svm
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score

lr=LogisticRegression()
lr.fit(X_train,y_train)

y_pred1=lr.predict(X_test)
print(accuracy_score(y_test,y_pred1))

svm = svm.SVC()
svm.fit(X_train,y_train)

y_pred2 = svm.predict(X_test)
print(accuracy_score(y_test,y_pred2))

knn=KNeighborsClassifier()
knn.fit(X_train,y_train)
y_pred3=knn.predict(X_test)
print(accuracy_score(y_test,y_pred2))

rf=RandomForestClassifier()
rf.fit(X_train,y_train)

y_pred4=rf.predict(X_test)
print(accuracy_score(y_test,y_pred4))

gr=GradientBoostingClassifier()
gr.fit(X_train,y_train)

y_pred5=lr.predict(X_test)
print(accuracy_score(y_test,y_pred5))

final_data = pd.DataFrame({'Models':['LR','SVC','KNN','RF','GBC'],
                           'ACC_SCORE':[accuracy_score(y_test,y_pred1),
                                        accuracy_score(y_test,y_pred2),
                                        accuracy_score(y_test,y_pred3),
                                        accuracy_score(y_test,y_pred4),
                                        accuracy_score(y_test,y_pred5)]})

final_data

import seaborn as sns

sns.barplot(x='Models', y='ACC_SCORE', data=final_data)



X=data.drop('Chance of Admit ',axis=1)

y=data['Chance of Admit ']

y=[1 if value >0.8 else 0 for value in y]

y=np.array(y)

y

X=sc.fit_transform(X)

gr=GradientBoostingClassifier()
gr.fit(X,y)

import joblib

joblib.dump(gr,'admission_model')

model = joblib.load('admission_model')

data.columns

model.predict(sc.transform([[337,118,4,4.5,4.5,9.65,1]]))





